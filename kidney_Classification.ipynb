{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "\n",
    "#Oversampling\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "from kmeans_smote import KMeansSMOTE\n",
    "\n",
    "\n",
    "### multiprocessing\n",
    "from multiprocessing.pool import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>SBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>etiology of CKD</th>\n",
       "      <th>Hb</th>\n",
       "      <th>Alb</th>\n",
       "      <th>Cr</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>CKD_stage</th>\n",
       "      <th>...</th>\n",
       "      <th>eGFR(6M)</th>\n",
       "      <th>eGFR(12M)</th>\n",
       "      <th>eGFR(18M)</th>\n",
       "      <th>eGFR(24M)</th>\n",
       "      <th>eGFR(30M)</th>\n",
       "      <th>eGFR(36M)</th>\n",
       "      <th>eGFR(last visit)</th>\n",
       "      <th>average_obs</th>\n",
       "      <th>obsevasion_ duration</th>\n",
       "      <th>fclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>120.0</td>\n",
       "      <td>23.137669</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>89.981926</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>26.454698</td>\n",
       "      <td>24.331582</td>\n",
       "      <td>24.682189</td>\n",
       "      <td>21.614854</td>\n",
       "      <td>20.420524</td>\n",
       "      <td>20.420524</td>\n",
       "      <td>18.495328</td>\n",
       "      <td>25.275139</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>139.0</td>\n",
       "      <td>28.515625</td>\n",
       "      <td>2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>88.330020</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>78.287758</td>\n",
       "      <td>71.343858</td>\n",
       "      <td>72.845992</td>\n",
       "      <td>71.908942</td>\n",
       "      <td>71.562914</td>\n",
       "      <td>67.225032</td>\n",
       "      <td>67.225032</td>\n",
       "      <td>72.392152</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>154.0</td>\n",
       "      <td>24.582701</td>\n",
       "      <td>4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.87</td>\n",
       "      <td>86.973875</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>75.027238</td>\n",
       "      <td>69.595257</td>\n",
       "      <td>68.856399</td>\n",
       "      <td>72.901926</td>\n",
       "      <td>69.749275</td>\n",
       "      <td>69.171408</td>\n",
       "      <td>69.171408</td>\n",
       "      <td>72.694258</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>144.0</td>\n",
       "      <td>30.737407</td>\n",
       "      <td>2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.22</td>\n",
       "      <td>86.874201</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>26.885061</td>\n",
       "      <td>24.917353</td>\n",
       "      <td>28.581660</td>\n",
       "      <td>29.237135</td>\n",
       "      <td>25.556002</td>\n",
       "      <td>25.183703</td>\n",
       "      <td>25.183703</td>\n",
       "      <td>26.485251</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>135.0</td>\n",
       "      <td>23.758726</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>86.782629</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>46.978867</td>\n",
       "      <td>45.829455</td>\n",
       "      <td>41.488436</td>\n",
       "      <td>41.801561</td>\n",
       "      <td>38.106104</td>\n",
       "      <td>38.106104</td>\n",
       "      <td>38.106104</td>\n",
       "      <td>43.081581</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age    SBP        BMI  etiology of CKD    Hb  Alb    Cr       eGFR  \\\n",
       "0       2   74  120.0  23.137669                2  12.0  4.0  1.20  89.981926   \n",
       "1       1   57  139.0  28.515625                2  15.9  4.8  0.84  88.330020   \n",
       "2       1   32  154.0  24.582701                4  14.4  4.4  0.87  86.973875   \n",
       "3       1   60  144.0  30.737407                2  14.4  4.7  2.22  86.874201   \n",
       "4       1   49  135.0  23.758726                2  17.0  4.1  1.39  86.782629   \n",
       "\n",
       "   CKD_stage  ...   eGFR(6M)  eGFR(12M)  eGFR(18M)  eGFR(24M)  eGFR(30M)  \\\n",
       "0          3  ...  26.454698  24.331582  24.682189  21.614854  20.420524   \n",
       "1          2  ...  78.287758  71.343858  72.845992  71.908942  71.562914   \n",
       "2          2  ...  75.027238  69.595257  68.856399  72.901926  69.749275   \n",
       "3          4  ...  26.885061  24.917353  28.581660  29.237135  25.556002   \n",
       "4          3  ...  46.978867  45.829455  41.488436  41.801561  38.106104   \n",
       "\n",
       "   eGFR(36M)  eGFR(last visit)  average_obs  obsevasion_ duration  fclass  \n",
       "0  20.420524         18.495328    25.275139                    37       0  \n",
       "1  67.225032         67.225032    72.392152                    37       0  \n",
       "2  69.171408         69.171408    72.694258                    36       0  \n",
       "3  25.183703         25.183703    26.485251                    35       0  \n",
       "4  38.106104         38.106104    43.081581                    30       0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('prepared Data.csv')\n",
    "print(data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 611, 1: 170, 5: 51, 2: 42, 6: 48})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(data['fclass'])\n",
    "count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>SBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>etiology of CKD</th>\n",
       "      <th>Hb</th>\n",
       "      <th>Alb</th>\n",
       "      <th>Cr</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>CKD_stage</th>\n",
       "      <th>...</th>\n",
       "      <th>eGFR(0M)</th>\n",
       "      <th>eGFR(6M)</th>\n",
       "      <th>eGFR(12M)</th>\n",
       "      <th>eGFR(18M)</th>\n",
       "      <th>eGFR(24M)</th>\n",
       "      <th>eGFR(30M)</th>\n",
       "      <th>eGFR(36M)</th>\n",
       "      <th>eGFR(last visit)</th>\n",
       "      <th>average_obs</th>\n",
       "      <th>obsevasion_ duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.274589</td>\n",
       "      <td>0.226723</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.236418</td>\n",
       "      <td>0.252488</td>\n",
       "      <td>0.34037</td>\n",
       "      <td>0.289644</td>\n",
       "      <td>0.213048</td>\n",
       "      <td>0.240891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317065</td>\n",
       "      <td>0.364381</td>\n",
       "      <td>0.445874</td>\n",
       "      <td>0.506843</td>\n",
       "      <td>0.620132</td>\n",
       "      <td>0.643818</td>\n",
       "      <td>0.733924</td>\n",
       "      <td>0.746836</td>\n",
       "      <td>0.461023</td>\n",
       "      <td>0.401767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender       age       SBP       BMI  etiology of CKD        Hb      Alb  \\\n",
       "0  0.141026  0.274589  0.226723  0.214286         0.236418  0.252488  0.34037   \n",
       "\n",
       "         Cr      eGFR  CKD_stage  ...  eGFR(0M)  eGFR(6M)  eGFR(12M)  \\\n",
       "0  0.289644  0.213048   0.240891  ...  0.317065  0.364381   0.445874   \n",
       "\n",
       "   eGFR(18M)  eGFR(24M)  eGFR(30M)  eGFR(36M)  eGFR(last visit)  average_obs  \\\n",
       "0   0.506843   0.620132   0.643818   0.733924          0.746836     0.461023   \n",
       "\n",
       "   obsevasion_ duration  \n",
       "0              0.401767  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# data = pd.read_csv(\"D://Blogs//train.csv\")\n",
    "# X = data.iloc[:,0:20]  #independent columns\n",
    "# y = data.iloc[:,-1]    #target column i.e price range\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "importances = dict()\n",
    "for col in data.iloc[:,:-1].columns:\n",
    "    importances[col] = 0\n",
    "\n",
    "for i in range(50):\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(data.iloc[:,:-1],data['fclass'])\n",
    "    matplotlib.rcParams['figure.figsize'] = (8.0, 6.0)\n",
    "    # print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "    #plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=data.iloc[:,:-1].columns)\n",
    "    for col in data.iloc[:,:-1].columns:\n",
    "        importances[col] += dict(feat_importances)[col]\n",
    "#     feat_importances.nlargest(5).plot(kind='barh')\n",
    "#     plt.show()\n",
    "    \n",
    "newpd = pd.DataFrame()\n",
    "for col in data.iloc[:,:-1].columns:\n",
    "    newpd[col] = list([importances[col]])\n",
    "newpd.to_csv('feature_importamce.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(data.iloc[:,:-1],data['fclass'])\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 6.0)\n",
    "# print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=data.iloc[:,:-1].columns)\n",
    "\n",
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4695713812580669"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances['age'] += dict(feat_importances)['age']\n",
    "importances['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40211984306286014"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 1 9]\n",
      " [0 2 0 1]\n",
      " [0 0 0 0]\n",
      " [0 0 1 3]]\n"
     ]
    }
   ],
   "source": [
    "CL = SVC(kernel='poly',gamma='scale',class_weight='balanced', C=8.0)\n",
    "model = CL.fit(data.values[:,:-1], data.values[:,-1])\n",
    "# model.predict(data.values[100:120,:-1])\n",
    "predict = model.predict(data.values[100:120,:-1])\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(data.values[100:120,-1], predict)\n",
    "# print(method)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "  \n",
    "# # defining parameter range for SVM\n",
    "# param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "#               'kernel': ['poly','rbf','sigmoid']}  \n",
    "  \n",
    "# grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# # fitting the model for grid search \n",
    "# grid.fit(data.values[:,:-1], data.values[:,-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = data.values[:int(800),:-1], data.values[:int(800),-1]\n",
    "# [print('Class {} has {} instances'.format(label, count))\n",
    "#  for label, count in zip(*np.unique(y, return_counts=True))]\n",
    "\n",
    "# kmeans_smote = KMeansSMOTE(\n",
    "#     kmeans_args={\n",
    "#         'n_clusters': 63\n",
    "#     },\n",
    "#     smote_args={\n",
    "#         'k_neighbors': 10\n",
    "#     }\n",
    "# )\n",
    "# X_resampled, y_resampled = kmeans_smote.fit_sample(X, y)\n",
    "\n",
    "# [print('Class {} has {} instances after oversampling'.format(label, count))\n",
    "#  for label, count in zip(*np.unique(y_resampled, return_counts=True))]\n",
    "# print(Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "# oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "## Below code works for binary classification \n",
    "# oversample = RandomOverSampler(sampling_strategy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # define oversampling strategy\n",
    "# oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# # fit and apply the transform\n",
    "# X_over, y_over = oversample.fit_resample(data.values[:,:-1], data.values[:,-1])\n",
    "\n",
    "# Max = dict(Counter(y_over))[0.0]\n",
    "# flag = True\n",
    "# while flag:\n",
    "#     X_over, y_over = oversample.fit_resample(X_over, y_over)\n",
    "#     for x in list(dict(Counter(y_over)).values()):\n",
    "#         if x == Max:\n",
    "#             flag = False\n",
    "#         else:\n",
    "#             flag = True\n",
    "#             break\n",
    "        \n",
    "# # summarize class distribution\n",
    "# print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adict = dict()\n",
    "# adict.update(zip(d.columns,col[:-1]))\n",
    "# adict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = pd.DataFrame(X_over)\n",
    "# adict = dict()\n",
    "# adict.update(zip(d.columns,col[:-1]))\n",
    "# d.rename(columns = adict, inplace =True)\n",
    "# d['fclass'] = y_over\n",
    "# d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = Counter(data['fclass'])\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat0 = shuffle(data[data['fclass']==0])\n",
    "cat1 = shuffle(data[data['fclass']==1])\n",
    "cat2 = shuffle(data[data['fclass']==2])\n",
    "cat5 = shuffle(data[data['fclass']==5])\n",
    "cat6 = shuffle(data[data['fclass']==6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lenCat0 = len(cat0.iloc[:,0])\n",
    "lenCat1 = len(cat1.iloc[:,0])\n",
    "lenCat2 = len(cat2.iloc[:,0])\n",
    "lenCat5 = len(cat5.iloc[:,0])\n",
    "lenCat6 = len(cat6.iloc[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodList = []\n",
    "accRes = []\n",
    "accConf = []\n",
    "nFold = 10\n",
    "# sensitivityList = []\n",
    "# specificityList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicMethods = ['Gradient Boosting','Support Vector Machine', 'Logistic Regression', 'K Neighbors Classifier',\\\n",
    "                'Random Forest', 'Gaussian Naive Bayes', 'Linear Discriminant Analysis', 'Decision Tree']\n",
    "\n",
    "methods = ['soft_VotingClassifier','hard_VotingClassifier', 'Gradient Boosting','Support Vector Machine',\\\n",
    "           'Logistic Regression', 'K Neighbors Classifier', 'Random Forest', 'Gaussian Naive Bayes',\\\n",
    "          'Linear Discriminant Analysis', 'Decision Tree']\n",
    "# methods = ['hard_VotingClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 10 fold-CV\n",
    "\n",
    "def classifiers(method):\n",
    "    if method == 'Logistic Regression':\n",
    "        CL = LogisticRegression()\n",
    "        \n",
    "    if method == 'K Neighbors Classifier':\n",
    "        CL = KNeighborsClassifier(n_neighbors=10)\n",
    "    if method == 'Random Forest':\n",
    "        CL = RandomForestClassifier(max_depth=35)\n",
    "    if method == 'Gaussian Naive Bayes':\n",
    "        CL = GaussianNB()\n",
    "    if method == 'Linear Discriminant Analysis':\n",
    "        CL = LinearDiscriminantAnalysis()\n",
    "    if method == 'Decision Tree':\n",
    "        CL = DecisionTreeClassifier()\n",
    "    if method == 'Support Vector Machine':\n",
    "        CL = SVC(C=0.1, gamma=0.0001, kernel='poly',probability=True)\n",
    "#         class_weight='balanced', C=1.0\n",
    "    if method == 'Gradient Boosting':\n",
    "        CL = GradientBoostingClassifier()\n",
    "    if method == 'soft_VotingClassifier':\n",
    "        cl1 = LogisticRegression()\n",
    "        cl2 = KNeighborsClassifier(n_neighbors=10)\n",
    "        cl3 = RandomForestClassifier(max_depth=35)\n",
    "        cl4 = GaussianNB()\n",
    "        cl5 = LinearDiscriminantAnalysis()\n",
    "        cl6 = DecisionTreeClassifier()\n",
    "        cl7 = SVC(C=0.1, gamma=0.0001, kernel='poly',probability=True)\n",
    "        cl8 = GradientBoostingClassifier()\n",
    "        estimator = [(basicMethods[0],cl1), (basicMethods[1],cl2), (basicMethods[2],cl3),\\\n",
    "                     (basicMethods[3],cl4), (basicMethods[4],cl5), (basicMethods[5],cl6),\\\n",
    "                     (basicMethods[6],cl7), (basicMethods[7],cl8)]\n",
    "        CL = VotingClassifier(estimators=estimator, voting='soft', weights=[6, 10, 5, 5, 10, 5, 6, 8])\n",
    "        \n",
    "    if method == 'hard_VotingClassifier':\n",
    "        cl1 = LogisticRegression()\n",
    "        cl2 = KNeighborsClassifier(n_neighbors=10)\n",
    "        cl3 = RandomForestClassifier(max_depth=35)\n",
    "        cl4 = GaussianNB()\n",
    "        cl5 = LinearDiscriminantAnalysis()\n",
    "        cl6 = DecisionTreeClassifier()\n",
    "        cl7 = SVC(C=0.1, gamma=0.0001, kernel='poly',probability=True)\n",
    "        cl8 = GradientBoostingClassifier()\n",
    "        estimator = [(basicMethods[0],cl1), (basicMethods[1],cl2), (basicMethods[2],cl3),\\\n",
    "                     (basicMethods[3],cl4), (basicMethods[4],cl5), (basicMethods[5],cl6),\\\n",
    "                     (basicMethods[6],cl7), (basicMethods[7],cl8)]\n",
    "        CL = VotingClassifier(estimators=estimator, voting='hard')\n",
    "    if method == 'stacking classifir':\n",
    "        estimator = [(basicMethods[0],cl1), (basicMethods[1],cl2), (basicMethods[2],cl3),\\\n",
    "             (basicMethods[3],cl4), (basicMethods[4],cl5), (basicMethods[5],cl6),\\\n",
    "             (basicMethods[6],cl7), (basicMethods[7],cl8)]\n",
    "        stacking = StackingClassifier(estimators=estimator)\n",
    "#     print(type(CL))\n",
    "    accList = []\n",
    "    for j in range(nFold):\n",
    "\n",
    "        i = j*.1\n",
    "        k = (j+1)*.1\n",
    "        #train\n",
    "        X_train = cat0.iloc[int(k * lenCat0):,:-1].append(\\\n",
    "                  cat1.iloc[int(k * lenCat1):,:-1].append(\\\n",
    "                  cat2.iloc[int(k * lenCat2):,:-1].append(\\\n",
    "                  cat5.iloc[int(k * lenCat5):,:-1].append(\\\n",
    "                  cat6.iloc[int(k * lenCat6):,:-1].append(\\\n",
    "                  cat0.iloc[:int(i * lenCat0),:-1].append(\\\n",
    "                  cat1.iloc[:int(i * lenCat1),:-1].append(\\\n",
    "                  cat2.iloc[:int(i * lenCat2),:-1].append(\\\n",
    "                  cat5.iloc[:int(i * lenCat5),:-1].append(\\\n",
    "                  cat6.iloc[:int(i * lenCat6),:-1]                                       \n",
    "                                                         )))))))))\n",
    "\n",
    "        y_train = cat0.iloc[int(k * lenCat0):,-1].append(\\\n",
    "                  cat1.iloc[int(k * lenCat1):,-1].append(\\\n",
    "                  cat2.iloc[int(k * lenCat2):,-1].append(\\\n",
    "                  cat5.iloc[int(k * lenCat5):,-1].append(\\\n",
    "                  cat6.iloc[int(k * lenCat6):,-1].append(\\\n",
    "                  cat0.iloc[:int(i * lenCat0),-1].append(\\\n",
    "                  cat1.iloc[:int(i * lenCat1),-1].append(\\\n",
    "                  cat2.iloc[:int(i * lenCat2),-1].append(\\\n",
    "                  cat5.iloc[:int(i * lenCat5),-1].append(\\\n",
    "                  cat6.iloc[:int(i * lenCat6),-1]                                         \n",
    "                                                        )))))))))\n",
    "#         print(X_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "        #preprocessing\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train_transformed = scaler.transform(X_train)\n",
    "        X_test_transformed = scaler.transform(X_test)    \n",
    "\n",
    "        # fit and apply the Oversampling:\n",
    "        #### Repeatitive oversampling\n",
    "#         X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "#         Max = dict(Counter(y_over))[0.0]\n",
    "#         flag = True\n",
    "#         while flag:\n",
    "#             X_over, y_over = oversample.fit_resample(X_over, y_over)\n",
    "#             for x in list(dict(Counter(y_over)).values()):\n",
    "#                 if x == Max:\n",
    "#                     flag = False\n",
    "#                 else:\n",
    "#                     flag = True\n",
    "#                     break\n",
    "#         X_train, y_train = X_over.copy(), y_over.copy()\n",
    "        # summarize class distribution\n",
    "#         print(Counter(y_train))\n",
    "\n",
    "#         print(X_train.shape, y_train.shape)\n",
    "    \n",
    "\n",
    "        # fit and apply the Oversampling:\n",
    "        #### K-means oversampling\n",
    "#         [print('Class {} has {} instances'.format(label, count))\n",
    "#          for label, count in zip(*np.unique(y, return_counts=True))]\n",
    "\n",
    "        kmeans_smote = KMeansSMOTE(\n",
    "            kmeans_args={\n",
    "                'n_clusters': 63\n",
    "            },\n",
    "            smote_args={\n",
    "                'k_neighbors': 10\n",
    "            }\n",
    "        )\n",
    "        X_train, y_train = kmeans_smote.fit_sample(X_train, y_train)\n",
    "\n",
    "#         [print('Class {} has {} instances after oversampling'.format(label, count))\n",
    "#          for label, count in zip(*np.unique(y_resampled, return_counts=True))]\n",
    "        # summarize class distribution\n",
    "#         print(Counter(y_train))\n",
    "\n",
    "        #test\n",
    "        X_test = cat0.iloc[int(i * lenCat0):int(k * lenCat0),:-1].append(\\\n",
    "                 cat1.iloc[int(i * lenCat1):int(k * lenCat1),:-1].append(\\\n",
    "                 cat2.iloc[int(i * lenCat2):int(k * lenCat2),:-1].append(\\\n",
    "                 cat5.iloc[int(i * lenCat5):int(k * lenCat5),:-1].append(\\\n",
    "                 cat6.iloc[int(i * lenCat6):int(k * lenCat6),:-1]))))\n",
    "\n",
    "        y_test = cat0.iloc[int(i * lenCat0):int(k * lenCat0),-1].append(\\\n",
    "                 cat1.iloc[int(i * lenCat1):int(k * lenCat1),-1].append(\\\n",
    "                 cat2.iloc[int(i * lenCat2):int(k * lenCat2),-1].append(\\\n",
    "                 cat5.iloc[int(i * lenCat5):int(k * lenCat5),-1].append(\\\n",
    "                 cat6.iloc[int(i * lenCat6):int(k * lenCat6),-1]))))\n",
    "#         print(X_test.shape, y_test.shape)\n",
    "\n",
    "        \n",
    "        model = CL.fit(X_train, np.array(list(y_train)))\n",
    "        \n",
    "        predict = np.array(model.predict(X_test))\n",
    "        \n",
    "        cnf_matrix = metrics.confusion_matrix(y_test, predict)\n",
    "#         print(method)\n",
    "#         print(cnf_matrix)\n",
    "#         #matplotlib inline\n",
    "#         class_names=[0,1] # name  of classes\n",
    "#         fig, ax = plt.subplots()\n",
    "#         tick_marks = np.arange(len(class_names))\n",
    "#         plt.xticks(tick_marks, class_names)\n",
    "#         plt.yticks(tick_marks, class_names)\n",
    "\n",
    "#         # create heatmap\n",
    "#         sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "#         ax.xaxis.set_label_position(\"top\")\n",
    "#         plt.tight_layout()\n",
    "#         plt.title(method+ ' fold of '+str(j), y=1.1)\n",
    "\n",
    "#         plt.ylabel('Actual label')\n",
    "#         plt.xlabel('Predicted label')\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "        acc = metrics.accuracy_score(y_test.values, predict)\n",
    "        accList.append(acc)\n",
    "\n",
    "\n",
    "    methodList.append(method)\n",
    "    confidence = 0.95\n",
    "\n",
    "    naccList = len(accList)\n",
    "    maccList = np.mean(accList)\n",
    "    std_erraccList = sem(accList)\n",
    "    haccList = std_erraccList * t.ppf((1 + confidence) / 2, naccList - 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     print(\"Accuracy:         \"+ str(round(maccList,2)) + '  -+' + str(round(haccList,4)))\n",
    "    accRes.append(round(maccList,2))\n",
    "    accConf.append(round(haccList,4))\n",
    "    return (method, round(maccList,2), round(haccList,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    p = Pool(processes=7)\n",
    "    result1 = p.map(classifiers, methods)\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result1)\n",
    "result.columns = ['Method','Accuracy','ACC CI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ACC CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soft_VotingClassifier</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard_VotingClassifier</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Method  Accuracy  ACC CI\n",
       "0         soft_VotingClassifier      0.58  0.0513\n",
       "1         hard_VotingClassifier      0.61  0.0389\n",
       "2             Gradient Boosting      0.72  0.0361\n",
       "3        Support Vector Machine      0.31  0.0346\n",
       "4           Logistic Regression      0.32  0.0349\n",
       "5        K Neighbors Classifier      0.42  0.0257\n",
       "6                 Random Forest      0.76  0.0387\n",
       "7          Gaussian Naive Bayes      0.41  0.0234\n",
       "8  Linear Discriminant Analysis      0.47  0.0428\n",
       "9                 Decision Tree      0.64  0.0238"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ACC CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soft_VotingClassifier</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard_VotingClassifier</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Method  Accuracy  ACC CI\n",
       "0         soft_VotingClassifier      0.58  0.0513\n",
       "1         hard_VotingClassifier      0.61  0.0389\n",
       "2             Gradient Boosting      0.72  0.0361\n",
       "3        Support Vector Machine      0.31  0.0346\n",
       "4           Logistic Regression      0.32  0.0349\n",
       "5        K Neighbors Classifier      0.42  0.0257\n",
       "6                 Random Forest      0.76  0.0387\n",
       "7          Gaussian Naive Bayes      0.41  0.0234\n",
       "8  Linear Discriminant Analysis      0.47  0.0428\n",
       "9                 Decision Tree      0.64  0.0238"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # result = []\n",
    "# result = pd.DataFrame(result1)\n",
    "# result['Method'],result['Accuracy'],result['ACC CI'] = methodList,accRes,accConf\n",
    "result.to_excel('kidney_Classification_Result_preprocess before oversampling.xlsx',index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
